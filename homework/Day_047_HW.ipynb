{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取酒類資料集\n",
    "digits = datasets.load_wine()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=42)\n",
    "\n",
    "# 建立模型\n",
    "reg = GradientBoostingRegressor(random_state=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14672894294872418\n"
     ]
    }
   ],
   "source": [
    "# 先看看使用預設參數得到的結果，約為 0.14 的 MSE\n",
    "reg.fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_test)\n",
    "print(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [50, 100, 150], 'max_depth': [1, 3, 5]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [50, 100, 150]\n",
    "max_depth = [1, 3, 5]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    2.9s finished\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 設定要訓練的超參數組合\n",
    "n_estimators = [50, 100, 150]\n",
    "max_depth = [1, 3, 5]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)\n",
    "\n",
    "## 建立搜尋物件，放入模型及參數組合字典 (n_jobs=-1 會使用全部 cpu 平行運算)\n",
    "grid_search = GridSearchCV(reg, param_grid, scoring=\"neg_mean_squared_error\", n_jobs=-1, verbose=1)\n",
    "\n",
    "# 開始搜尋最佳參數\n",
    "grid_result = grid_search.fit(x_train, y_train)\n",
    "\n",
    "# 預設會跑 3-fold cross-validadtion，總共 9 種參數組合，總共要 train 27 次模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: -0.080314 using {'max_depth': 1, 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# 印出最佳結果與最佳參數\n",
    "print(\"Best Accuracy: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'n_estimators': 150}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用最佳參數重新建立模型\n",
    "reg_bestparam = GradientBoostingRegressor(max_depth=grid_result.best_params_['max_depth'],\n",
    "                                           n_estimators=grid_result.best_params_['n_estimators'])\n",
    "\n",
    "# 訓練模型\n",
    "reg_bestparam.fit(x_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = reg_bestparam.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05207725857654407\n"
     ]
    }
   ],
   "source": [
    "# 調整參數後約可降至 0.05 的 MSE\n",
    "print(metrics.mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "了解如何使用 Sklearn 中的 hyper-parameter search 找出最佳的超參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業\n",
    "請使用不同的資料集，並使用 hyper-parameter search 的方式，看能不能找出最佳的超參數組合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=4)\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=4)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9688888888888889\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.0s\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:   33.0s finished\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "parameters = {\n",
    "    'loss':['deviance'],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'n_estimators':[20, 50, 100],\n",
    "    'max_depth':[1, 3, 5, 10]\n",
    "}\n",
    "\n",
    "folder = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "grid_search = GridSearchCV(clf, parameters, cv=folder, scoring='accuracy', n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_result = grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 0.953229 using {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Accuracy: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuuracy:  0.9711111111111111\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_result.best_estimator_.predict(x_test)\n",
    "\n",
    "acc = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Acuuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "num = 10\n",
    "indx = np.random.choice(len(x_test), num, replace=False)\n",
    "for i in range(num):\n",
    "    plt.subplot(num/5, 5, i+1)\n",
    "    plt.title(y_test[indx[i]])\n",
    "    plt.text(x=3, y=10, s='(' + str(y_pred[indx[i]]) + ')')\n",
    "    plt.imshow(x_test[indx[i]].reshape(8,8), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    #plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
