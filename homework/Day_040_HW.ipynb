{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取糖尿病資料集\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "regr.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  33.40877011 -292.24672884  481.07153405  369.06269614 -966.37849405\n",
      "  589.81383056  232.61924401  288.3263166   802.72704593   37.81285219]\n"
     ]
    }
   ],
   "source": [
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2939.42\n"
     ]
    }
   ],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取糖尿病資料集\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "lasso = linear_model.Lasso(alpha=1.0)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.        ,  -0.        , 321.203877  ,  57.74744332,\n",
       "         0.        ,   0.        ,  -0.        ,   0.        ,\n",
       "       332.41817196,   0.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 印出各特徵對應的係數，可以看到許多係數都變成 0，Lasso Regression 的確可以做特徵選取\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 3505.84\n"
     ]
    }
   ],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取糖尿病資料集\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# 切分訓練集/測試集\n",
    "x_train, x_test, y_train, y_test = train_test_split(diabetes.data, diabetes.target, test_size=0.2, random_state=4)\n",
    "\n",
    "# 建立一個線性回歸模型\n",
    "ridge = linear_model.Ridge(alpha=1.0)\n",
    "\n",
    "# 將訓練資料丟進去模型訓練\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "# 將測試資料丟進模型得到預測結果\n",
    "y_pred = regr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  48.8125786   -85.49511577  270.22532535  201.91767903   17.41308665\n",
      "  -19.04346706 -136.47737574  122.26503311  247.60074795   95.59855598]\n"
     ]
    }
   ],
   "source": [
    "# 印出 Ridge 的參數，可以很明顯看到比起 Linear Regression，參數的數值都明顯小了許多\n",
    "print(ridge.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 2939.42\n"
     ]
    }
   ],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看見 LASSO 與 Ridge 的結果並沒有比原本的線性回歸來得好，\n",
    "這是因為目標函數被加上了正規化函數，讓模型不能過於複雜，相當於限制模型擬和資料的能力。因此若沒有發現 Over-fitting 的情況，是可以不需要一開始就加上太強的正規化的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [作業重點]\n",
    "使用 Sklearn 中的 Lasso, Ridge 模型，來訓練各種資料集，務必了解送進去模型訓練的**資料型態**為何，也請了解模型中各項參數的意義。\n",
    "\n",
    "機器學習的模型非常多種，但要訓練的資料多半有固定的格式，確保你了解訓練資料的格式為何，這樣在應用新模型時，就能夠最快的上手開始訓練！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "請使用其他資料集 (boston, wine)，並調整不同的 alpha 來觀察模型訓練的情形。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boston House-Prices Dataset (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (506, 13)\n",
      "Features:  ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "boston = datasets.load_boston()\n",
    "print(\"Shape: \", boston.data.shape)\n",
    "print(\"Features: \", boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=4)\n",
    "\n",
    "linear = linear_model.LinearRegression()\n",
    "\n",
    "linear.fit(x_train, y_train)\n",
    "\n",
    "y_pred = linear.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.15966452e-01,  4.71249231e-02,  8.25980146e-03,  3.23404531e+00,\n",
       "       -1.66865890e+01,  3.88410651e+00, -1.08974442e-02, -1.54129540e+00,\n",
       "        2.93208309e-01, -1.34059383e-02, -9.06296429e-01,  8.80823439e-03,\n",
       "       -4.57723846e-01])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 25.42\n"
     ]
    }
   ],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = linear_model.Lasso(alpha=1.0)\n",
    "\n",
    "lasso.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lasso.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.06494981,  0.04581458, -0.        ,  0.        , -0.        ,\n",
       "        1.18140024,  0.01109101, -0.73695809,  0.23350042, -0.01551065,\n",
       "       -0.69270805,  0.00763157, -0.6927848 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 印出各特徵對應的係數，可以看到許多係數都變成 0，Lasso Regression 的確可以做特徵選取\n",
    "lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 28.95\n"
     ]
    }
   ],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Tune Hyperparameters (Regularization Strength alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  import sys\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4281.822264289693, tolerance: 3.3131348787128716\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "lasso_MSE = {}\n",
    "gap = np.linspace(0, 10, 101) #0, 0.1, 0.2, ..., 10\n",
    "\n",
    "for x in gap:\n",
    "    lasso = linear_model.Lasso(alpha=x)\n",
    "\n",
    "    lasso.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = lasso.predict(x_test)\n",
    "    \n",
    "    lasso_MSE[x] = round(mean_squared_error(y_test, y_pred), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>26.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>26.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>26.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>26.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>26.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>27.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>27.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>27.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>28.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.1</td>\n",
       "      <td>29.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.2</td>\n",
       "      <td>30.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.3</td>\n",
       "      <td>30.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.4</td>\n",
       "      <td>31.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.5</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.6</td>\n",
       "      <td>32.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.7</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.8</td>\n",
       "      <td>33.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.9</td>\n",
       "      <td>33.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>34.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.1</td>\n",
       "      <td>34.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.2</td>\n",
       "      <td>35.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.3</td>\n",
       "      <td>35.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.4</td>\n",
       "      <td>35.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.5</td>\n",
       "      <td>36.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.6</td>\n",
       "      <td>36.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.7</td>\n",
       "      <td>36.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.8</td>\n",
       "      <td>37.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.9</td>\n",
       "      <td>37.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7.1</td>\n",
       "      <td>44.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7.2</td>\n",
       "      <td>44.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7.3</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7.4</td>\n",
       "      <td>44.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7.5</td>\n",
       "      <td>44.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7.6</td>\n",
       "      <td>44.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>7.7</td>\n",
       "      <td>44.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>7.8</td>\n",
       "      <td>44.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>7.9</td>\n",
       "      <td>45.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8.0</td>\n",
       "      <td>45.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8.1</td>\n",
       "      <td>45.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8.2</td>\n",
       "      <td>45.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8.3</td>\n",
       "      <td>45.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8.4</td>\n",
       "      <td>45.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>8.5</td>\n",
       "      <td>45.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8.6</td>\n",
       "      <td>46.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8.7</td>\n",
       "      <td>46.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8.8</td>\n",
       "      <td>46.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>8.9</td>\n",
       "      <td>46.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9.0</td>\n",
       "      <td>46.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9.1</td>\n",
       "      <td>46.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9.2</td>\n",
       "      <td>46.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9.3</td>\n",
       "      <td>46.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>9.4</td>\n",
       "      <td>46.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9.5</td>\n",
       "      <td>47.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9.6</td>\n",
       "      <td>47.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9.7</td>\n",
       "      <td>47.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9.8</td>\n",
       "      <td>47.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>9.9</td>\n",
       "      <td>47.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10.0</td>\n",
       "      <td>47.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha    MSE\n",
       "0      0.0  25.42\n",
       "1      0.1  26.45\n",
       "2      0.2  26.60\n",
       "3      0.3  26.65\n",
       "4      0.4  26.76\n",
       "5      0.5  26.94\n",
       "6      0.6  27.22\n",
       "7      0.7  27.59\n",
       "8      0.8  27.98\n",
       "9      0.9  28.43\n",
       "10     1.0  28.95\n",
       "11     1.1  29.54\n",
       "12     1.2  30.19\n",
       "13     1.3  30.91\n",
       "14     1.4  31.66\n",
       "15     1.5  32.00\n",
       "16     1.6  32.37\n",
       "17     1.7  32.77\n",
       "18     1.8  33.19\n",
       "19     1.9  33.63\n",
       "20     2.0  34.09\n",
       "21     2.1  34.58\n",
       "22     2.2  35.08\n",
       "23     2.3  35.40\n",
       "24     2.4  35.73\n",
       "25     2.5  36.05\n",
       "26     2.6  36.37\n",
       "27     2.7  36.69\n",
       "28     2.8  37.02\n",
       "29     2.9  37.35\n",
       "..     ...    ...\n",
       "71     7.1  44.02\n",
       "72     7.2  44.15\n",
       "73     7.3  44.28\n",
       "74     7.4  44.41\n",
       "75     7.5  44.54\n",
       "76     7.6  44.67\n",
       "77     7.7  44.80\n",
       "78     7.8  44.93\n",
       "79     7.9  45.07\n",
       "80     8.0  45.20\n",
       "81     8.1  45.34\n",
       "82     8.2  45.47\n",
       "83     8.3  45.61\n",
       "84     8.4  45.75\n",
       "85     8.5  45.89\n",
       "86     8.6  46.03\n",
       "87     8.7  46.17\n",
       "88     8.8  46.31\n",
       "89     8.9  46.45\n",
       "90     9.0  46.59\n",
       "91     9.1  46.69\n",
       "92     9.2  46.79\n",
       "93     9.3  46.89\n",
       "94     9.4  46.99\n",
       "95     9.5  47.10\n",
       "96     9.6  47.20\n",
       "97     9.7  47.31\n",
       "98     9.8  47.41\n",
       "99     9.9  47.52\n",
       "100   10.0  47.63\n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lasso_MSE = sorted(lasso_MSE.items(), key=lambda kv: kv[1])\n",
    "sheet = pd.DataFrame(lasso_MSE)\n",
    "sheet = sheet.rename(columns={0:'alpha', 1:'MSE'})\n",
    "sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = linear_model.Ridge(alpha=1.0)\n",
    "\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.12499445e-01,  4.79562332e-02, -2.40438147e-02,  2.96199458e+00,\n",
       "       -9.33966118e+00,  3.93079015e+00, -1.73821202e-02, -1.43347691e+00,\n",
       "        2.75239392e-01, -1.38920708e-02, -8.31116943e-01,  9.15637729e-03,\n",
       "       -4.66460539e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 印出 Ridge 的參數，可以很明顯看到比起 Linear Regression，參數的數值都明顯小了許多\n",
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 25.74\n"
     ]
    }
   ],
   "source": [
    "# 預測值與實際值的差距，使用 MSE\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge Tune Hyperparameters (Regularization Strength alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "  \n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4281.822264289693, tolerance: 3.3131348787128716\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "ridge_MSE = {}\n",
    "\n",
    "for x in gap:\n",
    "    ridge = linear_model.Lasso(alpha=x)\n",
    "\n",
    "    ridge.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = ridge.predict(x_test)\n",
    "    \n",
    "    ridge_MSE[x] = round(mean_squared_error(y_test, y_pred), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>MSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>25.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>26.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>26.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>26.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>26.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>26.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6</td>\n",
       "      <td>27.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7</td>\n",
       "      <td>27.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.8</td>\n",
       "      <td>27.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.9</td>\n",
       "      <td>28.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.1</td>\n",
       "      <td>29.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.2</td>\n",
       "      <td>30.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.3</td>\n",
       "      <td>30.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.4</td>\n",
       "      <td>31.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.5</td>\n",
       "      <td>32.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.6</td>\n",
       "      <td>32.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.7</td>\n",
       "      <td>32.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.8</td>\n",
       "      <td>33.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.9</td>\n",
       "      <td>33.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.0</td>\n",
       "      <td>34.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.1</td>\n",
       "      <td>34.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.2</td>\n",
       "      <td>35.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.3</td>\n",
       "      <td>35.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.4</td>\n",
       "      <td>35.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.5</td>\n",
       "      <td>36.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.6</td>\n",
       "      <td>36.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.7</td>\n",
       "      <td>36.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.8</td>\n",
       "      <td>37.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.9</td>\n",
       "      <td>37.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>7.1</td>\n",
       "      <td>44.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>7.2</td>\n",
       "      <td>44.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>7.3</td>\n",
       "      <td>44.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>7.4</td>\n",
       "      <td>44.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>7.5</td>\n",
       "      <td>44.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7.6</td>\n",
       "      <td>44.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>7.7</td>\n",
       "      <td>44.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>7.8</td>\n",
       "      <td>44.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>7.9</td>\n",
       "      <td>45.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>8.0</td>\n",
       "      <td>45.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>8.1</td>\n",
       "      <td>45.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>8.2</td>\n",
       "      <td>45.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>8.3</td>\n",
       "      <td>45.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>8.4</td>\n",
       "      <td>45.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>8.5</td>\n",
       "      <td>45.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>8.6</td>\n",
       "      <td>46.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>8.7</td>\n",
       "      <td>46.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8.8</td>\n",
       "      <td>46.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>8.9</td>\n",
       "      <td>46.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>9.0</td>\n",
       "      <td>46.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>9.1</td>\n",
       "      <td>46.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>9.2</td>\n",
       "      <td>46.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>9.3</td>\n",
       "      <td>46.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>9.4</td>\n",
       "      <td>46.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9.5</td>\n",
       "      <td>47.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9.6</td>\n",
       "      <td>47.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9.7</td>\n",
       "      <td>47.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9.8</td>\n",
       "      <td>47.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>9.9</td>\n",
       "      <td>47.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>10.0</td>\n",
       "      <td>47.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha    MSE\n",
       "0      0.0  25.42\n",
       "1      0.1  26.45\n",
       "2      0.2  26.60\n",
       "3      0.3  26.65\n",
       "4      0.4  26.76\n",
       "5      0.5  26.94\n",
       "6      0.6  27.22\n",
       "7      0.7  27.59\n",
       "8      0.8  27.98\n",
       "9      0.9  28.43\n",
       "10     1.0  28.95\n",
       "11     1.1  29.54\n",
       "12     1.2  30.19\n",
       "13     1.3  30.91\n",
       "14     1.4  31.66\n",
       "15     1.5  32.00\n",
       "16     1.6  32.37\n",
       "17     1.7  32.77\n",
       "18     1.8  33.19\n",
       "19     1.9  33.63\n",
       "20     2.0  34.09\n",
       "21     2.1  34.58\n",
       "22     2.2  35.08\n",
       "23     2.3  35.40\n",
       "24     2.4  35.73\n",
       "25     2.5  36.05\n",
       "26     2.6  36.37\n",
       "27     2.7  36.69\n",
       "28     2.8  37.02\n",
       "29     2.9  37.35\n",
       "..     ...    ...\n",
       "71     7.1  44.02\n",
       "72     7.2  44.15\n",
       "73     7.3  44.28\n",
       "74     7.4  44.41\n",
       "75     7.5  44.54\n",
       "76     7.6  44.67\n",
       "77     7.7  44.80\n",
       "78     7.8  44.93\n",
       "79     7.9  45.07\n",
       "80     8.0  45.20\n",
       "81     8.1  45.34\n",
       "82     8.2  45.47\n",
       "83     8.3  45.61\n",
       "84     8.4  45.75\n",
       "85     8.5  45.89\n",
       "86     8.6  46.03\n",
       "87     8.7  46.17\n",
       "88     8.8  46.31\n",
       "89     8.9  46.45\n",
       "90     9.0  46.59\n",
       "91     9.1  46.69\n",
       "92     9.2  46.79\n",
       "93     9.3  46.89\n",
       "94     9.4  46.99\n",
       "95     9.5  47.10\n",
       "96     9.6  47.20\n",
       "97     9.7  47.31\n",
       "98     9.8  47.41\n",
       "99     9.9  47.52\n",
       "100   10.0  47.63\n",
       "\n",
       "[101 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_MSE = sorted(ridge_MSE.items(), key=lambda kv: kv[1])\n",
    "sheet = pd.DataFrame(ridge_MSE)\n",
    "sheet = sheet.rename(columns={0:'alpha', 1:'MSE'})\n",
    "sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結論<br>\n",
    "- Linear Regression MSE: 25.42\n",
    "- Lasso MSE: 28.95\n",
    "- Ridge MSE: 25.74\n",
    "- 在Boston Dataset Regularization 強度愈高 MSE 愈高"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Dataset (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class:  ['class_0' 'class_1' 'class_2']\n",
      "Shape:  (178, 13)\n",
      "Features:  ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "wine = datasets.load_wine()\n",
    "print(\"Class: \", wine.target_names)\n",
    "print(\"Shape: \", wine.data.shape)\n",
    "print(\"Features: \", wine.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + L1 Regularization C=1.0\n",
    "- penalty : str, ‘l1’, ‘l2’, ‘elasticnet’ or ‘none’, optional (default=’l2’)\n",
    "- C : float, optional (default=1.0) &emsp; Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=4)\n",
    "\n",
    "LR_L1 = linear_model.LogisticRegression(penalty='l1', C=1.0)\n",
    "\n",
    "LR_L1.fit(x_train, y_train)\n",
    "\n",
    "y_pred = LR_L1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.63508710e-01,  6.27499902e-01,  8.56613119e-01,\n",
       "        -5.53220856e-01, -4.32785071e-02,  0.00000000e+00,\n",
       "         1.21303292e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.03594989e-01,\n",
       "         1.77949145e-02],\n",
       "       [ 1.07295863e+00, -1.11065398e+00,  0.00000000e+00,\n",
       "         2.08255236e-01,  7.78607045e-03,  0.00000000e+00,\n",
       "         4.62976388e-01,  0.00000000e+00,  5.20817090e-01,\n",
       "        -2.03981772e+00,  7.20650532e-01,  0.00000000e+00,\n",
       "        -1.46553809e-02],\n",
       "       [-1.19823305e-01,  2.76294242e-01,  0.00000000e+00,\n",
       "         9.23617277e-02,  7.44891121e-03,  0.00000000e+00,\n",
       "        -2.89998760e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         9.72307059e-01,  0.00000000e+00, -1.52886011e+00,\n",
       "        -1.09659903e-04]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_L1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression + L1 Tune Hyperparameters (Regularization Strength alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso_auc = {}\n",
    "gap = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for x in gap:\n",
    "    LR_L1 = linear_model.LogisticRegression(penalty='l1', C=x)\n",
    "    \n",
    "    LR_L1.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = LR_L1.predict(x_test)\n",
    "    \n",
    "    lasso_auc[x] = round(accuracy_score(y_test, y_pred), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reverse_alpha</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reverse_alpha   AUC\n",
       "0          0.001  0.56\n",
       "1          0.010  0.58\n",
       "2          0.100  0.92\n",
       "3          1.000  0.97\n",
       "4         10.000  0.97\n",
       "5        100.000  1.00"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_auc = sorted(lasso_auc.items(), key=lambda kv: kv[1])\n",
    "sheet = pd.DataFrame(lasso_auc)\n",
    "sheet = sheet.rename(columns={0:'Reverse_alpha', 1:'AUC'})\n",
    "sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression + L2 Regularization C=1.0 Default Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ridge = linear_model.LogisticRegression(penalty='l2', C=1.0) #default setting\n",
    "\n",
    "ridge.fit(x_train, y_train)\n",
    "\n",
    "y_pred = ridge.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.82864779e-01,  7.19709566e-01,  9.78123238e-01,\n",
       "        -5.71326897e-01, -3.15688084e-02,  3.00522775e-01,\n",
       "         1.11716506e+00, -3.43549778e-02, -4.90150215e-01,\n",
       "        -1.05374113e-02, -1.54185796e-01,  9.61331414e-01,\n",
       "         1.81479366e-02],\n",
       "       [ 9.32405991e-01, -1.02836307e+00, -7.03687526e-01,\n",
       "         2.35034368e-01,  8.51406104e-03,  7.62359762e-02,\n",
       "         4.71638459e-01,  5.60638803e-01,  6.15085511e-01,\n",
       "        -1.81947987e+00,  9.33098198e-01,  7.36442197e-02,\n",
       "        -1.40242413e-02],\n",
       "       [-4.72180741e-01,  6.31034394e-01, -6.36847579e-02,\n",
       "         1.56380289e-01,  3.13408128e-02, -7.52374558e-01,\n",
       "        -1.62587954e+00, -1.31786834e-01, -7.01391158e-01,\n",
       "         1.03384290e+00, -4.87953685e-01, -1.15357424e+00,\n",
       "         1.40302540e-04]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression + L2 Tune Hyperparameters (Regularization Strength alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\tony8\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ridge_auc = {}\n",
    "gap = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for x in gap:\n",
    "    LR_L2 = linear_model.LogisticRegression(penalty='l2', C=x)\n",
    "    \n",
    "    LR_L2.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = LR_L2.predict(x_test)\n",
    "    \n",
    "    ridge_auc[x] = round(accuracy_score(y_test, y_pred), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reverse_alpha</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.000</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Reverse_alpha   AUC\n",
       "0          0.001  0.67\n",
       "1          0.010  0.86\n",
       "2          0.100  0.94\n",
       "3          1.000  0.97\n",
       "4         10.000  0.97\n",
       "5        100.000  0.97"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_auc = sorted(ridge_auc.items(), key=lambda kv: kv[1])\n",
    "sheet = pd.DataFrame(ridge_auc)\n",
    "sheet = sheet.rename(columns={0:'Reverse_alpha', 1:'AUC'})\n",
    "sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 結論<br>\n",
    "- Default Logistic Regression + L2 + C=1.0 &emsp; AUC: 97.2%\n",
    "- Logistic Regression + L1 + C=1.0 &emsp; AUC: 97.2%\n",
    "- C愈大 Regularization的強度愈低 (不同於Lasso & Ridge的alpha)\n",
    "- 在Wine Dataset Regularization強度愈高 AUC愈低"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
